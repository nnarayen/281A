{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from the JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import pandas\n",
    "\n",
    "business_ratings = { }\n",
    "for line in open(\"data/yelp_academic_dataset_business.json\", \"r\"):\n",
    "    json_data = json.loads(line)\n",
    "    business_ratings[json_data[\"business_id\"]] = json_data[\"stars\"]\n",
    "selected_businesses = set(np.random.choice(business_ratings.keys(), size = 2000, replace = False))\n",
    "    \n",
    "review_list = []\n",
    "for line in open(\"data/yelp_academic_dataset_review.json\", \"r\"):\n",
    "    json_data = json.loads(line)\n",
    "    if json_data[\"business_id\"] in selected_businesses:\n",
    "        review_list.append([json_data[\"review_id\"], json_data[\"stars\"], json_data[\"text\"], json_data[\"business_id\"]])\n",
    "review_pd = pandas.DataFrame(review_list, columns = [\"Review ID\", \"Stars\", \"Review Text\", \"Business ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tbl = dict.fromkeys(i for i in xrange(sys.maxunicode) if unicodedata.category(unichr(i)).startswith('P'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.translate(tbl).lower().split()\n",
    "\n",
    "review_pd[\"Tokenized Text\"] = review_pd[\"Review Text\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Business ID</th>\n",
       "      <th>Tokenized Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICfB48LBct5Q1AU_5bz5WA</td>\n",
       "      <td>4</td>\n",
       "      <td>As a chinese american college student from NYC...</td>\n",
       "      <td>Y2p07YEC8xOsYTHWf0UxiA</td>\n",
       "      <td>[as, a, chinese, american, college, student, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hqoYUZwXt43W3rL0nw7DgA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently pop in to this restaurant and got a...</td>\n",
       "      <td>Y2p07YEC8xOsYTHWf0UxiA</td>\n",
       "      <td>[i, recently, pop, in, to, this, restaurant, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-SOyFOGiDZRlC1ov0RT52w</td>\n",
       "      <td>3</td>\n",
       "      <td>Pretty solid Chinese takeout.  They have a $10...</td>\n",
       "      <td>Y2p07YEC8xOsYTHWf0UxiA</td>\n",
       "      <td>[pretty, solid, chinese, takeout, they, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pwm6ZRHqr0ubXu4QBaYpQw</td>\n",
       "      <td>2</td>\n",
       "      <td>Food: There are countless options to choose fr...</td>\n",
       "      <td>Y2p07YEC8xOsYTHWf0UxiA</td>\n",
       "      <td>[food, there, are, countless, options, to, cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mea6JnjvGDV51Wv6qyDiPQ</td>\n",
       "      <td>2</td>\n",
       "      <td>This place features everything you can expect ...</td>\n",
       "      <td>Y2p07YEC8xOsYTHWf0UxiA</td>\n",
       "      <td>[this, place, features, everything, you, can, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Review ID  Stars  \\\n",
       "0  ICfB48LBct5Q1AU_5bz5WA      4   \n",
       "1  hqoYUZwXt43W3rL0nw7DgA      4   \n",
       "2  -SOyFOGiDZRlC1ov0RT52w      3   \n",
       "3  pwm6ZRHqr0ubXu4QBaYpQw      2   \n",
       "4  Mea6JnjvGDV51Wv6qyDiPQ      2   \n",
       "\n",
       "                                         Review Text             Business ID  \\\n",
       "0  As a chinese american college student from NYC...  Y2p07YEC8xOsYTHWf0UxiA   \n",
       "1  I recently pop in to this restaurant and got a...  Y2p07YEC8xOsYTHWf0UxiA   \n",
       "2  Pretty solid Chinese takeout.  They have a $10...  Y2p07YEC8xOsYTHWf0UxiA   \n",
       "3  Food: There are countless options to choose fr...  Y2p07YEC8xOsYTHWf0UxiA   \n",
       "4  This place features everything you can expect ...  Y2p07YEC8xOsYTHWf0UxiA   \n",
       "\n",
       "                                      Tokenized Text  \n",
       "0  [as, a, chinese, american, college, student, f...  \n",
       "1  [i, recently, pop, in, to, this, restaurant, a...  \n",
       "2  [pretty, solid, chinese, takeout, they, have, ...  \n",
       "3  [food, there, are, countless, options, to, cho...  \n",
       "4  [this, place, features, everything, you, can, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data into LabeledSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import numpy as np\n",
    "\n",
    "class LabeledSentences:\n",
    "    \n",
    "    def __init__(self, series):\n",
    "        self.series = series\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indexes = list(np.arange(len(self.series)))\n",
    "        np.random.shuffle(indexes)\n",
    "        for (index, wordlist) in self.series.iloc[indexes].iteritems():\n",
    "            yield LabeledSentence(words = wordlist, tags = ['VEC_%s' % index])\n",
    "            \n",
    "sentences = LabeledSentences(review_pd[\"Tokenized Text\"].copy()[:12000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn vector representations for each word via Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be slow otherwise\"\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = Doc2Vec(dm = 1, dm_concat = 0, min_count = 1, window = 10, size = 30, sample = 1e-4, negative = 5, \n",
    "                workers = cores, alpha = 0.025, min_alpha = 0.025)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn vector representations for each review text via Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(sentences)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Concatenate Review Rating with Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "design_matrix, labels = [], []\n",
    "test_matrix, t_labels = [], []\n",
    "\n",
    "for index in xrange(len(model.docvecs)):\n",
    "    key = (\"VEC_%s\") % (index)\n",
    "    if index < 10500:\n",
    "        design_matrix.append(np.append(model.docvecs[key], review_pd[\"Stars\"][index]))\n",
    "        labels.append(business_ratings[review_pd[\"Business ID\"][index]])\n",
    "    else:\n",
    "        test_matrix.append(np.append(model.docvecs[key], review_pd[\"Stars\"][index]))\n",
    "        t_labels.append(business_ratings[review_pd[\"Business ID\"][index]])\n",
    "    \n",
    "design_matrix = np.array(design_matrix)\n",
    "labels = (np.array(labels) > 3).astype(int)\n",
    "\n",
    "test_matrix = np.array(test_matrix)\n",
    "t_labels = (np.array(t_labels) > 3).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data into Binomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(design_matrix, labels)\n",
    "\n",
    "preds = logreg.predict(test_matrix)\n",
    "print np.mean(preds == t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
