{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from the JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_SIZE = 1569264\n",
    "SAMPLE_SIZE = 130000\n",
    "TRAIN_SIZE = 25000\n",
    "GOAL = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_ratings = { }\n",
    "for line in open(\"data/yelp_academic_dataset_business.json\", \"r\"):\n",
    "    json_data = json.loads(line)\n",
    "    business_ratings[json_data[\"business_id\"]] = json_data[\"stars\"]\n",
    "#selected_businesses = set(np.random.choice(business_ratings.keys(), size = 2000, replace = False))\n",
    "    \n",
    "review_list = []\n",
    "\n",
    "selected = set(np.random.choice(np.arange(DATA_SIZE), size=SAMPLE_SIZE, replace=False))\n",
    "counters = {i: 0 for i in range(1, 6)}\n",
    "for line_num, line in enumerate(open(\"data/yelp_academic_dataset_review.json\", \"r\")):\n",
    "    if line_num in selected:\n",
    "        json_data = json.loads(line)\n",
    "        stars = json_data[\"stars\"]\n",
    "        if (counters[stars] < GOAL):\n",
    "            review_list.append([json_data[\"review_id\"], json_data[\"stars\"], json_data[\"text\"], json_data[\"business_id\"]])\n",
    "            counters[stars] += 1\n",
    "            \n",
    "review_pd = pandas.DataFrame(review_list, columns = [\"Review ID\", \"Stars\", \"Review Text\", \"Business ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "import unicodedata\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(unichr(i)).startswith('P'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.translate(tbl).lower().split()\n",
    "\n",
    "review_pd[\"Tokenized Text\"] = review_pd[\"Review Text\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Business ID</th>\n",
       "      <th>Tokenized Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review ID  Review Text  Business ID  Tokenized Text\n",
       "Stars                                                     \n",
       "1          10000        10000        10000           10000\n",
       "2          10000        10000        10000           10000\n",
       "3          10000        10000        10000           10000\n",
       "4          10000        10000        10000           10000\n",
       "5          10000        10000        10000           10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "review_pd.groupby(\"Stars\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_pd.to_json('data/review_multinomial.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data into LabeledSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_pd = pd.read_json('data/review_multinomial.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import numpy as np\n",
    "\n",
    "class LabeledSentences:\n",
    "    \n",
    "    def __init__(self, series):\n",
    "        self.series = series\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indexes = list(np.arange(len(self.series)))\n",
    "        np.random.shuffle(indexes)\n",
    "        for (index, wordlist) in self.series.iloc[indexes].iteritems():\n",
    "        #for (index, wordlist) in self.series.iteritems():\n",
    "            yield LabeledSentence(words = wordlist, tags = ['VEC_%s' % index])\n",
    "            \n",
    "sentences = LabeledSentences(review_pd[\"Tokenized Text\"].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn vector representations for each word via Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be slow otherwise\"\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = Doc2Vec(dm = 1, dm_concat = 0, min_count = 1, window = 10, size = 100, sample = 1e-4, negative = 5, \n",
    "                workers = cores, alpha = 0.03, min_alpha = 0.03)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn vector representations for each review text via Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(sentences)\n",
    "    #model.alpha -= 0.002\n",
    "    #model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Concatenate Review Rating with Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "# train_indices = set(np.random.choice(np.arange(len(model.docvecs)), replace=False, size=TRAIN_SIZE))\n",
    "for index in xrange(len(model.docvecs)):\n",
    "    key = (\"VEC_%s\") % (index)\n",
    "    \n",
    "    X.append(model.docvecs[key])\n",
    "    y.append(review_pd[\"Stars\"][index])\n",
    "\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y == 1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_Xs = []\n",
    "test_Xs = []\n",
    "train_ys = []\n",
    "test_ys = []\n",
    "for i in range(1, 6):\n",
    "    X_class_i = X[y == i, :]\n",
    "    y_class_i = y[y == i]\n",
    "    train_Xs.append(X_class_i[:X_class_i.shape[0] // 2, :])\n",
    "    test_Xs.append(X_class_i[X_class_i.shape[0] // 2:, :])\n",
    "    train_ys.append(y_class_i[:y_class_i.shape[0] // 2])\n",
    "    test_ys.append(y_class_i[y_class_i.shape[0] // 2:])\n",
    "    \n",
    "train_X = np.concatenate(train_Xs, axis=0)\n",
    "train_y = np.concatenate(train_ys, axis=0)\n",
    "test_X = np.concatenate(test_Xs, axis=0)\n",
    "test_y = np.concatenate(test_ys, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,  5000.,     0.,  5000.,     0.,  5000.,     0.,\n",
       "         5000.,     0.,  5000.]),\n",
       " array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "         5.5]),\n",
       " <a list of 11 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIwx8SWrE/wH2JkBj1tpCqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1359b8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_y,bins=[0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data into Binomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as met\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(train_X, train_y)\n",
    "\n",
    "preds = logreg.predict(test_X)\n",
    "print met.accuracy_score(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y_indicator = np.zeros((test_y.shape[0], 5))\n",
    "preds_indicator = np.zeros((test_y.shape[0], 5))\n",
    "for i in range(1, 6):\n",
    "    test_y_indicator[:, i-1] = (test_y == i).astype(int)\n",
    "    preds_indicator[:,i-1] = (preds == i).astype(int)\n",
    "\n",
    "#test_y_indicator = np.concatenate(test_y_indicator, axis=1)\n",
    "#preds_indicator = np.concatenate(preds_indicator, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50139999999999996"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met.accuracy_score(test_y_indicator, preds_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54915742052014749"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met.average_precision_score(test_y_indicator, preds_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: size = 20\n",
      "accuracy: 0.4602\n",
      "average precision: 0.509918532548\n",
      "training: size = 40\n",
      "accuracy: 0.4786\n",
      "average precision: 0.527859685395\n",
      "training: size = 60\n",
      "accuracy: 0.49448\n",
      "average precision: 0.542344882695\n",
      "training: size = 80\n",
      "accuracy: 0.499\n",
      "average precision: 0.546566394801\n",
      "training: size = 100\n",
      "accuracy: 0.49824\n",
      "average precision: 0.545698931296\n",
      "training: size = 120\n",
      "accuracy: 0.50008\n",
      "average precision: 0.547482420424\n",
      "training: size = 140\n",
      "accuracy: 0.50824\n",
      "average precision: 0.554840165505\n"
     ]
    }
   ],
   "source": [
    "s = 20\n",
    "step = 20\n",
    "\n",
    "\n",
    "while s < 160:\n",
    "    print \"training: size = %s\" % s \n",
    "    cores = multiprocessing.cpu_count()\n",
    "\n",
    "    model = Doc2Vec(min_count = 1, window = 10, size = s, sample = 1e-4, negative = 5, \n",
    "                    workers = cores, alpha = 0.025, min_alpha = 0.025)\n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train(sentences)\n",
    "        #model.alpha -= 0.002\n",
    "        #model.min_alpha = model.alpha\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    # train_indices = set(np.random.choice(np.arange(len(model.docvecs)), replace=False, size=TRAIN_SIZE))\n",
    "    for index in xrange(len(model.docvecs)):\n",
    "        key = (\"VEC_%s\") % (index)\n",
    "\n",
    "        X.append(model.docvecs[key])\n",
    "        y.append(review_pd[\"Stars\"][index])\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    train_Xs = []\n",
    "    test_Xs = []\n",
    "    train_ys = []\n",
    "    test_ys = []\n",
    "    for i in range(1, 6):\n",
    "        X_class_i = X[y == i, :]\n",
    "        y_class_i = y[y == i]\n",
    "        train_Xs.append(X_class_i[:X_class_i.shape[0] // 2, :])\n",
    "        test_Xs.append(X_class_i[X_class_i.shape[0] // 2:, :])\n",
    "        train_ys.append(y_class_i[:y_class_i.shape[0] // 2])\n",
    "        test_ys.append(y_class_i[y_class_i.shape[0] // 2:])\n",
    "\n",
    "    train_X = np.concatenate(train_Xs, axis=0)\n",
    "    train_y = np.concatenate(train_ys, axis=0)\n",
    "    test_X = np.concatenate(test_Xs, axis=0)\n",
    "    test_y = np.concatenate(test_ys, axis=0)\n",
    "    \n",
    "    logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "    logreg.fit(train_X, train_y)\n",
    "\n",
    "    preds = logreg.predict(test_X)\n",
    "    \n",
    "    test_y_indicator = np.zeros((test_y.shape[0], 5))\n",
    "    preds_indicator = np.zeros((test_y.shape[0], 5))\n",
    "    for i in range(1, 6):\n",
    "        test_y_indicator[:, i-1] = (test_y == i).astype(int)\n",
    "        preds_indicator[:,i-1] = (preds == i).astype(int)\n",
    "    \n",
    "    print \"accuracy: %s\" % met.accuracy_score(test_y_indicator, preds_indicator)  \n",
    "    print \"average precision: %s\" % met.average_precision_score(test_y_indicator, preds_indicator)\n",
    "\n",
    "    s += step\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
